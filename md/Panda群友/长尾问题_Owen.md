# CVPR21：CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning

### 1. 论文信息

题目：CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning



### 2. 引言

首先介绍本文涉及的两个概念，半监督学习和长尾分布。之所以会有半监督学习这种学习范式，是因为在现实生活中，有标注的数据非常难以收集，而获得高精度的标注也非常消耗时间和精力，而无标签的数据易于获取，更适合高效地收集更多的训练信息。而纯粹采用无标注的自然图像有会可能非常难以优化。在这种情况下，半监督学习（Semi-Supervised Learning）更适用于现实世界中的应用，近来也已成为深度学习领域热门的新方向，该方法的训练数据包括少量有带标签的样本，以及大量无标签的样本用于表征学习。与此同时，在实际应用中，我们得到的训练样本通常表现为长尾类分布，其中一小部分的类别具有大量的样本点，而其他类只与少数样本相关。然而，这种训练样本数量的类不平衡，使得基于深度网络的识别模型的训练非常具有挑战性。很显然，在样本类别不平衡的情况下，训练后的模型更倾向于把测试样本预测成头部的类别，即可能在头部过拟合，在尾部欠拟合，这样的训练数据分布导致模型可能在测试阶段泛化性能有限。在长尾的非平衡数据的监督学习已经被广泛研究。通常的方法包括重采样冒充甲醛，或者两阶段的学习。但局限性也非常明显就是非常依赖于标注。而我们自然可能会思考，如果是在没有或者仅有较少标注的情况下，如何进行表征的学习呢？

其实相较于全监督条件下的long-tail distribution学习，相比之下，long-tail distribution数据上的Semi-Supervised Learning还没有得到足够的研究。事实上，数据不平衡在SSL中带来了进一步的挑战，因为缺少标签信息阻碍了对未标记集的再平衡。在SSL算法中，通常利用对标记数据进行训练的模型生成的未标记数据的伪标签。然而，伪标签可能是“有问题的，如果它们是由一个在不平衡的数据上训练的初始模型生成的，并且倾向于大多数类:使用这种有偏见的伪标签的后续训练加剧了这种bias，并导致模型泛化能力有限。由于大多数现有的SSL算法还没有对不平衡数据分布进行彻底评估，但这个问题在真实世界中又普遍存在，因此本文提出了从这个角度来进行研究和深入。

![](https://img-blog.csdnimg.cn/dfb08f2ef53b460eb6c1a0379ad3783b.png)

如上图所示，本文首先发现了一个现象，就是现有SSL算法在不平衡数据上的不理想性能主要是体现在由于对少数类的召回率低。我们的方法的动机是进一步观察，尽管如此，对少数的class的精确度是非常高。在图1(b)中，我们展示了对FixMatch这一自监督方法在CIFARI0-LT数据集的性能，可以发现该模型在多数类上召回率较高，但在少数类上召回率较低，这导致在平衡测试集上总体精度较低。然而，该模型对少数类具有几乎完美的精度，这表明该模型在将样本划分为少数类方面是保守的，但一旦它做出了这样的预测，我们可以确信它是正确的。在其他SSL方法和监督学习，论文提出了一种类再平衡自训练方案 class-rebalancing self-training  scheme(CReST)，它在自适应地从未标记集采样伪标记数据之后，重新训练SSL模型的baseline，以补充原始的标注。每进行一次完整的标注后，就将未标记集合中的伪标签样本添加到标记的集中，以重新训练SSL模型。同时方法使用一种随机更新策略，在这种策略中，如果样本被预测为少数类，则以更高的概率选择样本，因为它们更有可能是正确的预测。更新概率是由标记集估计的数据分布的函数。此外，我们将CReST扩展为CReST+，方法是将domain adaptation分布对齐与温度缩放因子结合在一起，以控制其在几代之间的对齐强度，从而更积极地调整预测数据分布，以减轻模型偏差。如所提策略降低了伪标记的偏差，提高了类平衡测试集的精度。

### 3. 方法

论文首先详细分析了长尾分布表现一般的原因，就是很多尾部类别被分到了头部类别中。头部类别的recall都很高，相对的尾部类别的precision更好。

![](https://img-blog.csdnimg.cn/f67e9d929b3d42d0a09d3d8e8440319d.png)

其实方法还是比较直接的，上文已经完成了简单的基本介绍，其实论文提出方法的整体思路还是延续了经典半监督学习的范式：

- 使用标准的 SSL 算法利用已标记集和未标记集的信息训练一个有效的模型
- 给未标记集 mu 中的每个样本打上伪标记得到新的数据集 μ^
- 挑选出模型的预测类别属于尾部类别的样本作为候选集 s 加入到已标记集合中

每个类别l中伪标签样本被选择的比率为：

![](https://img-blog.csdnimg.cn/img_convert/2caeb680bcdcc769b910f158aff2fe5a.png)

参数设定成0的时候，这个方法就是正常的的self-training，所有的被打上了伪标签的类都被选中了。这个方法就是要我们在每一类选择伪标签样本时，选取置信度最高的。

其实具体来看，本文high-level的idea非常有意思，因为模型预测的类别中，对于尾部类别意味着这些样本的伪标记具有很高的置信度的，可见模型其实对头部类别过拟合的，因此引入伪标签的思路。而从另一方面，这一采样又巧妙的引入了尾部类别样本，从而缓解了类别不平衡问题。

另外，模型还加入了两个小模块来作为小改进，其实可能主要是为了提升性能。

### 4. 实验

![](https://img-blog.csdnimg.cn/7f068d5e7f9e42fd82170b6fc49219ae.png)

可见，论文提出的方法，相较于传统的半监督学习范式还是比较有帮助的。

另外，对于超参数，本文还做出了一些探索，但是整体来讲是符合预期的，因此没有什么特别要强调的地方。

![](https://img-blog.csdnimg.cn/880f0404da464f0c97f1a72094805786.png)

我们可以发现，引入了CReST，论文一开始提到的对于尾部类别的现象，的确会有所缓解。

### 5. 结论

在这项工作中，我们提出了一个名为CReST的类再平衡自我训练框架，用于不平衡半监督学习。CReST的动机是观察到现有SSL算法在少数类上产生高精度伪标签。CReST通过用高质量的伪标签补充标记集，迭代地改进基线SSL模型，其中少数类比多数类更新得更postive。通过不断地更新和生成，得到的质量也在不断的改善。